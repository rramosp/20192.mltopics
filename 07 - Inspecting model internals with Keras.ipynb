{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data and train a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension de las imagenes y las clases (1500, 784) (1500,)\n",
      "(1200, 784) (1200, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = pd.read_csv(\"data/mnist1.5k.csv.gz\", compression=\"gzip\", header=None).values\n",
    "X=mnist[:,1:785]/255.\n",
    "y=mnist[:,0]\n",
    "print \"dimension de las imagenes y las clases\", X.shape, y.shape\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "X_train = X_train\n",
    "X_test  = X_test\n",
    "y_train_oh = np.eye(10)[y_train]\n",
    "y_test_oh  = np.eye(10)[y_test]\n",
    "print X_train.shape, y_train_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, concatenate, Input\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim=784, output_dim=10, layer_sizes=[10]*6, activation=\"relu\", sigma=1):\n",
    "    \n",
    "    clear_session()\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(layer_sizes[0], activation=activation, input_dim=input_dim, name=\"Layer_%02d_Input\"%(0)))\n",
    "   \n",
    "    for i, hsize in enumerate(layer_sizes[1:]):\n",
    "        model.add(Dense(hsize, activation=activation, name=\"Layer_%02d_Hidden\"%(i+1)))\n",
    "   \n",
    "    model.add(Dense(output_dim, activation=\"softmax\", name=\"Layer_%02d_Output\"%(len(layer_sizes))))\n",
    "        \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.reset_states()\n",
    "    return model\n",
    "\n",
    "def get_tensors_and_functions(model):\n",
    "    T_input     = model.input                                        \n",
    "    T_outputs   = [layer.output for layer in model.layers]         \n",
    "    T_weights   = model.trainable_weights\n",
    "    T_gradients = model.optimizer.get_gradients(model.total_loss, T_weights)\n",
    "    F_outputs   = [K.function([T_input, K.learning_phase()], [out]) for out in T_outputs]    \n",
    "    F_gradients = [K.function(inputs=[T_input, model.targets[0],  \n",
    "                                      K.learning_phase()], outputs=[grad]) for grad in T_gradients]\n",
    "\n",
    "    return T_input, T_outputs, T_weights, T_gradients, F_outputs, F_gradients\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Layer_00_Input (Dense)       (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "Layer_01_Hidden (Dense)      (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "Layer_02_Hidden (Dense)      (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "Layer_03_Output (Dense)      (None, 10)                160       \n",
      "=================================================================\n",
      "Total params: 16,415\n",
      "Trainable params: 16,415\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(layer_sizes=[20,15,15], activation=\"sigmoid\", sigma=20)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/30\n",
      "1200/1200 [==============================] - 0s 246us/step - loss: 2.3124 - acc: 0.1225 - val_loss: 2.2823 - val_acc: 0.1300\n",
      "Epoch 2/30\n",
      "1200/1200 [==============================] - 0s 51us/step - loss: 2.2706 - acc: 0.1225 - val_loss: 2.2532 - val_acc: 0.1300\n",
      "Epoch 3/30\n",
      "1200/1200 [==============================] - 0s 57us/step - loss: 2.2412 - acc: 0.1925 - val_loss: 2.2279 - val_acc: 0.2733\n",
      "Epoch 4/30\n",
      "1200/1200 [==============================] - 0s 55us/step - loss: 2.2110 - acc: 0.2233 - val_loss: 2.1967 - val_acc: 0.2767\n",
      "Epoch 5/30\n",
      "1200/1200 [==============================] - 0s 54us/step - loss: 2.1748 - acc: 0.2758 - val_loss: 2.1598 - val_acc: 0.2967\n",
      "Epoch 6/30\n",
      "1200/1200 [==============================] - 0s 51us/step - loss: 2.1308 - acc: 0.3142 - val_loss: 2.1156 - val_acc: 0.3233\n",
      "Epoch 7/30\n",
      "1200/1200 [==============================] - 0s 54us/step - loss: 2.0798 - acc: 0.3592 - val_loss: 2.0663 - val_acc: 0.3433\n",
      "Epoch 8/30\n",
      "1200/1200 [==============================] - 0s 55us/step - loss: 2.0254 - acc: 0.3458 - val_loss: 2.0116 - val_acc: 0.3467\n",
      "Epoch 9/30\n",
      "1200/1200 [==============================] - 0s 49us/step - loss: 1.9677 - acc: 0.3608 - val_loss: 1.9551 - val_acc: 0.3933\n",
      "Epoch 10/30\n",
      "1200/1200 [==============================] - 0s 51us/step - loss: 1.9094 - acc: 0.3958 - val_loss: 1.9011 - val_acc: 0.4100\n",
      "Epoch 11/30\n",
      "1200/1200 [==============================] - 0s 52us/step - loss: 1.8533 - acc: 0.4167 - val_loss: 1.8465 - val_acc: 0.4400\n",
      "Epoch 12/30\n",
      "1200/1200 [==============================] - 0s 56us/step - loss: 1.7970 - acc: 0.4533 - val_loss: 1.7918 - val_acc: 0.4600\n",
      "Epoch 13/30\n",
      "1200/1200 [==============================] - 0s 52us/step - loss: 1.7406 - acc: 0.4917 - val_loss: 1.7437 - val_acc: 0.4833\n",
      "Epoch 14/30\n",
      "1200/1200 [==============================] - 0s 60us/step - loss: 1.6863 - acc: 0.4983 - val_loss: 1.6934 - val_acc: 0.4967\n",
      "Epoch 15/30\n",
      "1200/1200 [==============================] - 0s 55us/step - loss: 1.6333 - acc: 0.5367 - val_loss: 1.6379 - val_acc: 0.5433\n",
      "Epoch 16/30\n",
      "1200/1200 [==============================] - 0s 64us/step - loss: 1.5799 - acc: 0.5817 - val_loss: 1.5866 - val_acc: 0.6067\n",
      "Epoch 17/30\n",
      "1200/1200 [==============================] - 0s 83us/step - loss: 1.5247 - acc: 0.6242 - val_loss: 1.5395 - val_acc: 0.6200\n",
      "Epoch 18/30\n",
      "1200/1200 [==============================] - 0s 62us/step - loss: 1.4730 - acc: 0.6500 - val_loss: 1.4936 - val_acc: 0.6300\n",
      "Epoch 19/30\n",
      "1200/1200 [==============================] - 0s 59us/step - loss: 1.4204 - acc: 0.6750 - val_loss: 1.4444 - val_acc: 0.6633\n",
      "Epoch 20/30\n",
      "1200/1200 [==============================] - 0s 57us/step - loss: 1.3686 - acc: 0.7067 - val_loss: 1.4018 - val_acc: 0.6867\n",
      "Epoch 21/30\n",
      "1200/1200 [==============================] - 0s 58us/step - loss: 1.3182 - acc: 0.7258 - val_loss: 1.3502 - val_acc: 0.7000\n",
      "Epoch 22/30\n",
      "1200/1200 [==============================] - 0s 60us/step - loss: 1.2701 - acc: 0.7375 - val_loss: 1.3095 - val_acc: 0.7233\n",
      "Epoch 23/30\n",
      "1200/1200 [==============================] - 0s 56us/step - loss: 1.2179 - acc: 0.7658 - val_loss: 1.2634 - val_acc: 0.7367\n",
      "Epoch 24/30\n",
      "1200/1200 [==============================] - 0s 55us/step - loss: 1.1688 - acc: 0.7800 - val_loss: 1.2250 - val_acc: 0.7267\n",
      "Epoch 25/30\n",
      "1200/1200 [==============================] - 0s 63us/step - loss: 1.1217 - acc: 0.7833 - val_loss: 1.1782 - val_acc: 0.7433\n",
      "Epoch 26/30\n",
      "1200/1200 [==============================] - 0s 61us/step - loss: 1.0750 - acc: 0.7908 - val_loss: 1.1423 - val_acc: 0.7367\n",
      "Epoch 27/30\n",
      "1200/1200 [==============================] - 0s 60us/step - loss: 1.0302 - acc: 0.8092 - val_loss: 1.1040 - val_acc: 0.7500\n",
      "Epoch 28/30\n",
      "1200/1200 [==============================] - 0s 66us/step - loss: 0.9874 - acc: 0.8167 - val_loss: 1.0674 - val_acc: 0.7600\n",
      "Epoch 29/30\n",
      "1200/1200 [==============================] - 0s 60us/step - loss: 0.9461 - acc: 0.8217 - val_loss: 1.0349 - val_acc: 0.7500\n",
      "Epoch 30/30\n",
      "1200/1200 [==============================] - 0s 62us/step - loss: 0.9074 - acc: 0.8467 - val_loss: 1.0028 - val_acc: 0.7700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe6238203d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_oh, epochs=30, batch_size=32, validation_data=(X_test, y_test_oh))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we inspect programmatically the model structure with keras\n",
    "\n",
    "### first, we obtain the actual weights resulting from training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0.weights (784, 20)\n",
      "Layer 0.bias    (20,)\n",
      "Layer 1.weights (20, 15)\n",
      "Layer 1.bias    (15,)\n",
      "Layer 2.weights (15, 15)\n",
      "Layer 2.bias    (15,)\n",
      "Layer 3.weights (15, 10)\n",
      "Layer 3.bias    (10,)\n",
      "[[ 0.0854574  -0.01121411 -0.07872698 ...  0.03293201 -0.07051304\n",
      "  -0.03227102]\n",
      " [-0.02943881 -0.0524538  -0.05883778 ...  0.00605047 -0.07455608\n",
      "   0.0093073 ]\n",
      " [-0.06323884 -0.01824278 -0.04742123 ... -0.03132806  0.03482614\n",
      "  -0.05789207]\n",
      " ...\n",
      " [-0.08065084  0.01609161 -0.03099156 ... -0.07194784 -0.07325022\n",
      "  -0.08259846]\n",
      " [ 0.07844497 -0.06734192 -0.01589244 ... -0.06441855 -0.01728046\n",
      "  -0.07093646]\n",
      " [-0.03380889  0.00098854 -0.00087801 ...  0.07089812  0.00543009\n",
      "   0.08114362]]\n"
     ]
    }
   ],
   "source": [
    "mW = model.get_weights()\n",
    "W = [{\"weights\": mW[i], \"bias\": mW[i+1]} for i in range(0,len(mW),2)]\n",
    "for i in range(len(W)):\n",
    "    print \"Layer %i.weights\"%i, W[i][\"weights\"].shape\n",
    "    print \"Layer %i.bias   \"%i, W[i][\"bias\"].shape   \n",
    "    \n",
    "print W[0][\"weights\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### then, we obtain tensors representing:\n",
    "\n",
    "- the input\n",
    "- each layer output\n",
    "- all weights\n",
    "- all gradients\n",
    "\n",
    "### and functions for:\n",
    " - each layer output\n",
    " - gradients at for each layer weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_input, T_outputs, T_weights, T_gradients, F_outputs, F_gradients = get_tensors_and_functions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Layer_00_Input_input:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Layer_00_Input/Sigmoid:0' shape=(?, 20) dtype=float32>,\n",
       " <tf.Tensor 'Layer_01_Hidden/Sigmoid:0' shape=(?, 15) dtype=float32>,\n",
       " <tf.Tensor 'Layer_02_Hidden/Sigmoid:0' shape=(?, 15) dtype=float32>,\n",
       " <tf.Tensor 'Layer_03_Output/Softmax:0' shape=(?, 10) dtype=float32>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Layer_00_Input/kernel:0' shape=(784, 20) dtype=float32>,\n",
       " <tf.Variable 'Layer_00_Input/bias:0' shape=(20,) dtype=float32>,\n",
       " <tf.Variable 'Layer_01_Hidden/kernel:0' shape=(20, 15) dtype=float32>,\n",
       " <tf.Variable 'Layer_01_Hidden/bias:0' shape=(15,) dtype=float32>,\n",
       " <tf.Variable 'Layer_02_Hidden/kernel:0' shape=(15, 15) dtype=float32>,\n",
       " <tf.Variable 'Layer_02_Hidden/bias:0' shape=(15,) dtype=float32>,\n",
       " <tf.Variable 'Layer_03_Output/kernel:0' shape=(15, 10) dtype=float32>,\n",
       " <tf.Variable 'Layer_03_Output/bias:0' shape=(10,) dtype=float32>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'gradients/Layer_00_Input/MatMul_grad/MatMul_1:0' shape=(784, 20) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_00_Input/BiasAdd_grad/BiasAddGrad:0' shape=(20,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_01_Hidden/MatMul_grad/MatMul_1:0' shape=(20, 15) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_01_Hidden/BiasAdd_grad/BiasAddGrad:0' shape=(15,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_02_Hidden/MatMul_grad/MatMul_1:0' shape=(15, 15) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_02_Hidden/BiasAdd_grad/BiasAddGrad:0' shape=(15,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_03_Output/MatMul_grad/MatMul_1:0' shape=(15, 10) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_03_Output/BiasAdd_grad/BiasAddGrad:0' shape=(10,) dtype=float32>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.backend.Function at 0x7fe60839e290>,\n",
       " <tensorflow.python.keras.backend.Function at 0x7fe600e15c90>,\n",
       " <tensorflow.python.keras.backend.Function at 0x7fe600e15dd0>,\n",
       " <tensorflow.python.keras.backend.Function at 0x7fe600e15d10>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.backend.Function at 0x7fe600e15ed0>,\n",
       " <tensorflow.python.keras.backend.Function at 0x7fe600e15a50>,\n",
       " <tensorflow.python.keras.backend.Function at 0x7fe600e153d0>,\n",
       " <tensorflow.python.keras.backend.Function at 0x7fe600e15d50>,\n",
       " <tensorflow.python.keras.backend.Function at 0x7fe600e15f10>,\n",
       " <tensorflow.python.keras.backend.Function at 0x7fe600e15810>,\n",
       " <tensorflow.python.keras.backend.Function at 0x7fe600e159d0>,\n",
       " <tensorflow.python.keras.backend.Function at 0x7fe600e15e10>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we can use the function to compute stuff along the network\n",
    "\n",
    "**the output at input Layer when feeding test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9925572e-01, 6.8598098e-01, 9.9338442e-01, ..., 9.9206948e-01,\n",
       "        7.9237133e-02, 8.2446670e-05],\n",
       "       [5.6180918e-01, 1.7351142e-01, 9.6524376e-01, ..., 5.3034639e-01,\n",
       "        2.9003173e-01, 9.0523285e-01],\n",
       "       [5.9033161e-01, 4.5797002e-02, 6.0888708e-01, ..., 9.0797287e-01,\n",
       "        4.2905856e-02, 5.7273901e-01],\n",
       "       ...,\n",
       "       [9.5197862e-01, 9.1209847e-01, 9.4509572e-01, ..., 1.9726287e-01,\n",
       "        8.7464845e-01, 2.8903246e-01],\n",
       "       [1.0615108e-01, 4.1520588e-02, 9.8952043e-01, ..., 9.9077904e-01,\n",
       "        8.0399960e-03, 9.8582965e-01],\n",
       "       [9.7455716e-01, 9.2131841e-01, 9.9937457e-01, ..., 1.3440552e-02,\n",
       "        8.4667742e-01, 9.7441065e-01]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_outputs[0]([X_test])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and its equivalent if we do the math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99255738e-01, 6.85981069e-01, 9.93384412e-01, ...,\n",
       "        9.92069477e-01, 7.92371239e-02, 8.24466345e-05],\n",
       "       [5.61809196e-01, 1.73511400e-01, 9.65243777e-01, ...,\n",
       "        5.30346307e-01, 2.90031727e-01, 9.05232805e-01],\n",
       "       [5.90331607e-01, 4.57970137e-02, 6.08887145e-01, ...,\n",
       "        9.07972914e-01, 4.29058518e-02, 5.72738975e-01],\n",
       "       ...,\n",
       "       [9.51978653e-01, 9.12098440e-01, 9.45095699e-01, ...,\n",
       "        1.97262837e-01, 8.74648457e-01, 2.89032437e-01],\n",
       "       [1.06151024e-01, 4.15205827e-02, 9.89520412e-01, ...,\n",
       "        9.90778996e-01, 8.03999250e-03, 9.85829668e-01],\n",
       "       [9.74557111e-01, 9.21318475e-01, 9.99374585e-01, ...,\n",
       "        1.34405510e-02, 8.46677396e-01, 9.74410686e-01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigm = lambda x: 1./(1.+np.exp(-x))\n",
    "sigm(X_test.dot(W[0][\"weights\"])+W[0][\"bias\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the output at layer 0, before the sigmoid**\n",
    "\n",
    "- we need to dig into the computational graph.\n",
    "- `T_outputs[0].op.inputs[0]` points to the input of the sigmoid function, this is $XW+b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Layer_00_Input/BiasAdd:0' shape=(?, 20) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_outputs[0].op.inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Layer_00_Input/BiasAdd:0' shape=(?, 20) dtype=float32>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_outputs[2].op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.525766  , -1.2806816 ,  5.7874255 , ..., -6.6928325 ,\n",
       "        -6.759761  , -7.21748   ],\n",
       "       [-2.6858194 , -3.9190145 , -0.2410748 , ...,  2.8822815 ,\n",
       "        -4.4343596 ,  0.34144154],\n",
       "       [ 3.805331  ,  0.03930556, -4.1999183 , ..., -0.15553896,\n",
       "         2.0873923 ,  2.8933284 ],\n",
       "       ...,\n",
       "       [-1.6795448 , -3.4854717 ,  0.26783133, ..., -7.661979  ,\n",
       "        -1.0682076 , -4.7425723 ],\n",
       "       [ 4.2392316 , -3.4454932 , -2.1926055 , ...,  0.2599843 ,\n",
       "        -2.072024  ,  0.7256183 ],\n",
       "       [ 1.2503372 , -2.0729759 ,  3.2294497 , ...,  0.5349731 ,\n",
       "        -0.3932572 , -1.5482113 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XW0 = K.function([T_input, K.learning_phase()], [T_outputs[0].op.inputs[0]])\n",
    "XW0([X_test])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and doing the math, just to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.52576734, -1.28068038,  5.78742667, ..., -6.69283146,\n",
       "        -6.75976061, -7.21747983],\n",
       "       [-2.68582081, -3.91901502, -0.24107492, ...,  2.88228122,\n",
       "        -4.43436037,  0.34144168],\n",
       "       [ 3.80533089,  0.03930536, -4.19991729, ..., -0.15553898,\n",
       "         2.08739207,  2.89332803],\n",
       "       ...,\n",
       "       [-1.67954472, -3.48547067,  0.26783183, ..., -7.66197909,\n",
       "        -1.06820756, -4.74257307],\n",
       "       [ 4.23923166, -3.445493  , -2.19260521, ...,  0.2599845 ,\n",
       "        -2.07202403,  0.72561823],\n",
       "       [ 1.25033728, -2.07297541,  3.22944972, ...,  0.53497253,\n",
       "        -0.39325731, -1.54821119]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dot(W[0][\"weights\"])+W[0][\"bias\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the gradients of params at layer 0**\n",
    "\n",
    "observe how we need to feed **both** input and output to the gradients function. Output has to be in one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = F_gradients[0]([X_train, y_train_oh])[0]\n",
    "print g.shape\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We now inspect the distributions of weights, outputs and gradients of Layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_layer0_output():\n",
    "    weights=W[0][\"weights\"]\n",
    "    bias=W[0][\"bias\"]\n",
    "    O = (X_train.dot(weights)+bias).reshape(-1)\n",
    "    S = sigm(O)\n",
    "    plt.figure(figsize=(20,3))\n",
    "    plt.subplot(141)\n",
    "    plt.hist(O, bins=30, density=True);\n",
    "    plt.xlabel(\"$XW_{0}+b_{0}$\")\n",
    "    plt.subplot(142)\n",
    "    plt.hist(S, bins=30, density=True);\n",
    "    plt.xlabel(\"$sigm(XW_0+b_0)$\")\n",
    "    plt.subplot(143)\n",
    "    plt.hist(weights.reshape(-1), bins=30,density=True);\n",
    "    plt.xlabel(\"$W_{0}$\")\n",
    "    plt.subplot(144)\n",
    "    g = F_gradients[0]([X_train, y_train_oh])[0].reshape(-1)\n",
    "    plt.hist(g, bins=30,density=True);\n",
    "    plt.xlabel(\"gradients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_layer0_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
