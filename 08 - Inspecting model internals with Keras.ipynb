{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data and train a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension de las imagenes y las clases (1500, 784) (1500,)\n",
      "(1200, 784) (1200, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = pd.read_csv(\"data/mnist1.5k.csv.gz\", compression=\"gzip\", header=None).values\n",
    "X=mnist[:,1:785]/255.\n",
    "y=mnist[:,0]\n",
    "print (\"dimension de las imagenes y las clases\", X.shape, y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "X_train = X_train\n",
    "X_test  = X_test\n",
    "y_train_oh = np.eye(10)[y_train]\n",
    "y_test_oh  = np.eye(10)[y_test]\n",
    "print (X_train.shape, y_train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, concatenate, Input\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim=784, output_dim=10, layer_sizes=[10]*6, activation=\"relu\", sigma=1):\n",
    "    \n",
    "    clear_session()\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(layer_sizes[0], activation=activation, input_dim=input_dim, name=\"Layer_%02d_Input\"%(0)))\n",
    "   \n",
    "    for i, hsize in enumerate(layer_sizes[1:]):\n",
    "        model.add(Dense(hsize, activation=activation, name=\"Layer_%02d_Hidden\"%(i+1)))\n",
    "   \n",
    "    model.add(Dense(output_dim, activation=\"softmax\", name=\"Layer_%02d_Output\"%(len(layer_sizes))))\n",
    "        \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.reset_states()\n",
    "    return model\n",
    "\n",
    "def get_tensors_and_functions(model):\n",
    "    T_input     = model.input                                        \n",
    "    T_outputs   = [layer.output for layer in model.layers]         \n",
    "    T_weights   = model.trainable_weights\n",
    "    T_gradients = model.optimizer.get_gradients(model.total_loss, T_weights)\n",
    "    F_outputs   = [K.function([T_input, K.learning_phase()], [out]) for out in T_outputs]    \n",
    "    F_gradients = [K.function(inputs=[T_input, model.targets[0],  \n",
    "                                      K.learning_phase()], outputs=[grad]) for grad in T_gradients]\n",
    "\n",
    "    return T_input, T_outputs, T_weights, T_gradients, F_outputs, F_gradients\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/.conda/envs/p37/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Layer_00_Input (Dense)       (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "Layer_01_Hidden (Dense)      (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "Layer_02_Hidden (Dense)      (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "Layer_03_Output (Dense)      (None, 10)                160       \n",
      "=================================================================\n",
      "Total params: 16,415\n",
      "Trainable params: 16,415\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(layer_sizes=[20,15,15], activation=\"sigmoid\", sigma=20)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "WARNING:tensorflow:From /home/user/.conda/envs/p37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "1200/1200 [==============================] - 0s 208us/sample - loss: 2.5293 - acc: 0.1000 - val_loss: 2.3443 - val_acc: 0.1233\n",
      "Epoch 2/30\n",
      "1200/1200 [==============================] - 0s 65us/sample - loss: 2.3768 - acc: 0.1000 - val_loss: 2.2754 - val_acc: 0.1233\n",
      "Epoch 3/30\n",
      "1200/1200 [==============================] - 0s 58us/sample - loss: 2.3053 - acc: 0.1000 - val_loss: 2.2337 - val_acc: 0.1233\n",
      "Epoch 4/30\n",
      "1200/1200 [==============================] - 0s 66us/sample - loss: 2.2541 - acc: 0.1000 - val_loss: 2.1952 - val_acc: 0.1233\n",
      "Epoch 5/30\n",
      "1200/1200 [==============================] - 0s 84us/sample - loss: 2.2055 - acc: 0.1592 - val_loss: 2.1466 - val_acc: 0.2167\n",
      "Epoch 6/30\n",
      "1200/1200 [==============================] - 0s 70us/sample - loss: 2.1505 - acc: 0.1692 - val_loss: 2.0904 - val_acc: 0.2533\n",
      "Epoch 7/30\n",
      "1200/1200 [==============================] - 0s 63us/sample - loss: 2.0886 - acc: 0.2450 - val_loss: 2.0289 - val_acc: 0.3067\n",
      "Epoch 8/30\n",
      "1200/1200 [==============================] - 0s 56us/sample - loss: 2.0257 - acc: 0.3150 - val_loss: 1.9659 - val_acc: 0.3200\n",
      "Epoch 9/30\n",
      "1200/1200 [==============================] - 0s 49us/sample - loss: 1.9635 - acc: 0.3325 - val_loss: 1.9071 - val_acc: 0.3433\n",
      "Epoch 10/30\n",
      "1200/1200 [==============================] - 0s 45us/sample - loss: 1.9019 - acc: 0.3567 - val_loss: 1.8489 - val_acc: 0.3733\n",
      "Epoch 11/30\n",
      "1200/1200 [==============================] - 0s 64us/sample - loss: 1.8403 - acc: 0.3667 - val_loss: 1.7924 - val_acc: 0.3767\n",
      "Epoch 12/30\n",
      "1200/1200 [==============================] - 0s 54us/sample - loss: 1.7777 - acc: 0.3775 - val_loss: 1.7354 - val_acc: 0.4067\n",
      "Epoch 13/30\n",
      "1200/1200 [==============================] - 0s 55us/sample - loss: 1.7153 - acc: 0.4267 - val_loss: 1.6767 - val_acc: 0.4200\n",
      "Epoch 14/30\n",
      "1200/1200 [==============================] - 0s 49us/sample - loss: 1.6528 - acc: 0.4342 - val_loss: 1.6208 - val_acc: 0.4267\n",
      "Epoch 15/30\n",
      "1200/1200 [==============================] - 0s 61us/sample - loss: 1.5928 - acc: 0.5100 - val_loss: 1.5702 - val_acc: 0.4700\n",
      "Epoch 16/30\n",
      "1200/1200 [==============================] - 0s 55us/sample - loss: 1.5365 - acc: 0.5500 - val_loss: 1.5207 - val_acc: 0.4933\n",
      "Epoch 17/30\n",
      "1200/1200 [==============================] - 0s 57us/sample - loss: 1.4831 - acc: 0.5700 - val_loss: 1.4746 - val_acc: 0.5500\n",
      "Epoch 18/30\n",
      "1200/1200 [==============================] - 0s 64us/sample - loss: 1.4305 - acc: 0.6400 - val_loss: 1.4343 - val_acc: 0.5833\n",
      "Epoch 19/30\n",
      "1200/1200 [==============================] - 0s 55us/sample - loss: 1.3813 - acc: 0.6675 - val_loss: 1.3934 - val_acc: 0.5900\n",
      "Epoch 20/30\n",
      "1200/1200 [==============================] - 0s 55us/sample - loss: 1.3383 - acc: 0.6900 - val_loss: 1.3551 - val_acc: 0.6167\n",
      "Epoch 21/30\n",
      "1200/1200 [==============================] - 0s 53us/sample - loss: 1.2932 - acc: 0.7158 - val_loss: 1.3211 - val_acc: 0.6200\n",
      "Epoch 22/30\n",
      "1200/1200 [==============================] - 0s 55us/sample - loss: 1.2555 - acc: 0.7167 - val_loss: 1.2897 - val_acc: 0.6033\n",
      "Epoch 23/30\n",
      "1200/1200 [==============================] - 0s 70us/sample - loss: 1.2171 - acc: 0.7333 - val_loss: 1.2599 - val_acc: 0.6500\n",
      "Epoch 24/30\n",
      "1200/1200 [==============================] - 0s 55us/sample - loss: 1.1816 - acc: 0.7408 - val_loss: 1.2315 - val_acc: 0.6400\n",
      "Epoch 25/30\n",
      "1200/1200 [==============================] - 0s 62us/sample - loss: 1.1463 - acc: 0.7292 - val_loss: 1.2103 - val_acc: 0.6333\n",
      "Epoch 26/30\n",
      "1200/1200 [==============================] - 0s 59us/sample - loss: 1.1136 - acc: 0.7475 - val_loss: 1.1830 - val_acc: 0.6667\n",
      "Epoch 27/30\n",
      "1200/1200 [==============================] - 0s 55us/sample - loss: 1.0836 - acc: 0.7475 - val_loss: 1.1562 - val_acc: 0.6533\n",
      "Epoch 28/30\n",
      "1200/1200 [==============================] - 0s 57us/sample - loss: 1.0539 - acc: 0.7725 - val_loss: 1.1375 - val_acc: 0.6600\n",
      "Epoch 29/30\n",
      "1200/1200 [==============================] - 0s 66us/sample - loss: 1.0251 - acc: 0.7733 - val_loss: 1.1171 - val_acc: 0.6633\n",
      "Epoch 30/30\n",
      "1200/1200 [==============================] - 0s 54us/sample - loss: 0.9971 - acc: 0.7708 - val_loss: 1.0934 - val_acc: 0.6533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f301e24c278>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_oh, epochs=30, batch_size=32, validation_data=(X_test, y_test_oh))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we inspect programmatically the model structure with keras\n",
    "\n",
    "### first, we obtain the actual weights resulting from training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0.weights (784, 20)\n",
      "Layer 0.bias    (20,)\n",
      "Layer 1.weights (20, 15)\n",
      "Layer 1.bias    (15,)\n",
      "Layer 2.weights (15, 15)\n",
      "Layer 2.bias    (15,)\n",
      "Layer 3.weights (15, 10)\n",
      "Layer 3.bias    (10,)\n",
      "[[-0.03443924 -0.00238148  0.01480068 ...  0.0112726  -0.0825302\n",
      "   0.01180405]\n",
      " [ 0.07089245 -0.07286802 -0.07535192 ...  0.01091126  0.04079525\n",
      "   0.06651439]\n",
      " [ 0.07510205 -0.01404362  0.0516184  ...  0.00151736  0.07651143\n",
      "   0.07134171]\n",
      " ...\n",
      " [-0.01438238  0.00559779  0.0227362  ... -0.04969458  0.00553783\n",
      "  -0.04501259]\n",
      " [ 0.01181132  0.05136217 -0.08011606 ...  0.04674883  0.00631781\n",
      "  -0.07835934]\n",
      " [ 0.05129735  0.04655932 -0.08471573 ...  0.02702058 -0.03029588\n",
      "  -0.00102819]]\n"
     ]
    }
   ],
   "source": [
    "mW = model.get_weights()\n",
    "W = [{\"weights\": mW[i], \"bias\": mW[i+1]} for i in range(0,len(mW),2)]\n",
    "for i in range(len(W)):\n",
    "    print (\"Layer %i.weights\"%i, W[i][\"weights\"].shape)\n",
    "    print (\"Layer %i.bias   \"%i, W[i][\"bias\"].shape   )\n",
    "    \n",
    "print (W[0][\"weights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### then, we obtain tensors representing:\n",
    "\n",
    "- the input\n",
    "- each layer output\n",
    "- all weights\n",
    "- all gradients\n",
    "\n",
    "### and functions for:\n",
    " - each layer output\n",
    " - gradients at for each layer weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_input, T_outputs, T_weights, T_gradients, F_outputs, F_gradients = get_tensors_and_functions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Layer_00_Input_input:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Layer_00_Input/Sigmoid:0' shape=(?, 20) dtype=float32>,\n",
       " <tf.Tensor 'Layer_01_Hidden/Sigmoid:0' shape=(?, 15) dtype=float32>,\n",
       " <tf.Tensor 'Layer_02_Hidden/Sigmoid:0' shape=(?, 15) dtype=float32>,\n",
       " <tf.Tensor 'Layer_03_Output/Softmax:0' shape=(?, 10) dtype=float32>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Layer_00_Input/kernel:0' shape=(784, 20) dtype=float32>,\n",
       " <tf.Variable 'Layer_00_Input/bias:0' shape=(20,) dtype=float32>,\n",
       " <tf.Variable 'Layer_01_Hidden/kernel:0' shape=(20, 15) dtype=float32>,\n",
       " <tf.Variable 'Layer_01_Hidden/bias:0' shape=(15,) dtype=float32>,\n",
       " <tf.Variable 'Layer_02_Hidden/kernel:0' shape=(15, 15) dtype=float32>,\n",
       " <tf.Variable 'Layer_02_Hidden/bias:0' shape=(15,) dtype=float32>,\n",
       " <tf.Variable 'Layer_03_Output/kernel:0' shape=(15, 10) dtype=float32>,\n",
       " <tf.Variable 'Layer_03_Output/bias:0' shape=(10,) dtype=float32>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'gradients/Layer_00_Input/MatMul_grad/MatMul_1:0' shape=(784, 20) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_00_Input/BiasAdd_grad/BiasAddGrad:0' shape=(20,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_01_Hidden/MatMul_grad/MatMul_1:0' shape=(20, 15) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_01_Hidden/BiasAdd_grad/BiasAddGrad:0' shape=(15,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_02_Hidden/MatMul_grad/MatMul_1:0' shape=(15, 15) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_02_Hidden/BiasAdd_grad/BiasAddGrad:0' shape=(15,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_03_Output/MatMul_grad/MatMul_1:0' shape=(15, 10) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Layer_03_Output/BiasAdd_grad/BiasAddGrad:0' shape=(10,) dtype=float32>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.backend.GraphExecutionFunction at 0x7f3041c28128>,\n",
       " <tensorflow.python.keras.backend.GraphExecutionFunction at 0x7f301fbd3b00>,\n",
       " <tensorflow.python.keras.backend.GraphExecutionFunction at 0x7f30166baa90>,\n",
       " <tensorflow.python.keras.backend.GraphExecutionFunction at 0x7f301636de48>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.backend.GraphExecutionFunction at 0x7f301fbd3c18>,\n",
       " <tensorflow.python.keras.backend.GraphExecutionFunction at 0x7f301fbd3f28>,\n",
       " <tensorflow.python.keras.backend.GraphExecutionFunction at 0x7f301fbd3ef0>,\n",
       " <tensorflow.python.keras.backend.GraphExecutionFunction at 0x7f301fbd3eb8>,\n",
       " <tensorflow.python.keras.backend.GraphExecutionFunction at 0x7f301fbd3f98>,\n",
       " <tensorflow.python.keras.backend.GraphExecutionFunction at 0x7f301fbd3fd0>,\n",
       " <tensorflow.python.keras.backend.GraphExecutionFunction at 0x7f301fbd3cf8>,\n",
       " <tensorflow.python.keras.backend.GraphExecutionFunction at 0x7f301fbd3f60>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we can use the function to compute stuff along the network\n",
    "\n",
    "**the output at input Layer when feeding test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03880924, 0.06122208, 0.99341106, ..., 0.9745477 , 0.99470127,\n",
       "        0.00266472],\n",
       "       [0.33530396, 0.9980502 , 0.01646429, ..., 0.9879525 , 0.7460462 ,\n",
       "        0.66868705],\n",
       "       [0.36736047, 0.9858327 , 0.01900828, ..., 0.8312223 , 0.99076086,\n",
       "        0.00531802],\n",
       "       ...,\n",
       "       [0.07552645, 0.9930215 , 0.02449641, ..., 0.9855243 , 0.51385033,\n",
       "        0.39826375],\n",
       "       [0.7581127 , 0.7499939 , 0.17297423, ..., 0.95885646, 0.9167014 ,\n",
       "        0.0892258 ],\n",
       "       [0.4931406 , 0.950323  , 0.13040483, ..., 0.7938317 , 0.852847  ,\n",
       "        0.10235044]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_outputs[0]([X_test])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and its equivalent if we do the math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03880932, 0.06122206, 0.99341106, ..., 0.97454767, 0.99470121,\n",
       "        0.00266475],\n",
       "       [0.33530419, 0.99805023, 0.01646431, ..., 0.98795249, 0.74604621,\n",
       "        0.66868701],\n",
       "       [0.36736039, 0.98583274, 0.01900827, ..., 0.83122228, 0.99076089,\n",
       "        0.00531796],\n",
       "       ...,\n",
       "       [0.07552647, 0.99302153, 0.02449637, ..., 0.98552431, 0.51385031,\n",
       "        0.3982637 ],\n",
       "       [0.7581127 , 0.74999375, 0.17297422, ..., 0.95885656, 0.91670138,\n",
       "        0.08922584],\n",
       "       [0.49314063, 0.95032298, 0.13040486, ..., 0.79383166, 0.85284695,\n",
       "        0.10235047]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigm = lambda x: 1./(1.+np.exp(-x))\n",
    "sigm(X_test.dot(W[0][\"weights\"])+W[0][\"bias\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the output at layer 0, before the sigmoid**\n",
    "\n",
    "- we need to dig into the computational graph.\n",
    "- `T_outputs[0].op.inputs[0]` points to the input of the sigmoid function, this is $XW+b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Layer_00_Input/BiasAdd:0' shape=(?, 20) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_outputs[0].op.inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Layer_00_Input/BiasAdd:0' shape=(?, 20) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_outputs[2].op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.2095125 , -2.7300708 ,  5.015752  , ...,  3.6451666 ,\n",
       "         5.2349644 , -5.924978  ],\n",
       "       [-0.6842925 ,  6.238092  , -4.0899596 , ...,  4.4067764 ,\n",
       "         1.0776353 ,  0.7022529 ],\n",
       "       [-0.54355735,  4.242552  , -3.9436903 , ...,  1.5943148 ,\n",
       "         4.6750274 , -5.2313333 ],\n",
       "       ...,\n",
       "       [-2.5047412 ,  4.9579225 , -3.684429  , ...,  4.220703  ,\n",
       "         0.05541544, -0.41270486],\n",
       "       [ 1.1423603 ,  1.0985796 , -1.5646933 , ...,  3.148677  ,\n",
       "         2.3983495 , -2.3231242 ],\n",
       "       [-0.02743932,  2.95126   , -1.897384  , ...,  1.3481787 ,\n",
       "         1.7571069 , -2.1713767 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XW0 = K.function([T_input, K.learning_phase()], [T_outputs[0].op.inputs[0]])\n",
    "XW0([X_test])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and doing the math, just to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.2095123 , -2.73007135,  5.01575198, ...,  3.64516612,\n",
       "         5.23496473, -5.9249778 ],\n",
       "       [-0.68429136,  6.23808995, -4.08995864, ...,  4.40677664,\n",
       "         1.07763524,  0.70225257],\n",
       "       [-0.54355755,  4.24255269, -3.94368999, ...,  1.59431465,\n",
       "         4.67502726, -5.2313332 ],\n",
       "       ...,\n",
       "       [-2.50474125,  4.95792289, -3.68442904, ...,  4.22070317,\n",
       "         0.05541543, -0.41270497],\n",
       "       [ 1.14236015,  1.09857894, -1.56469334, ...,  3.14867691,\n",
       "         2.39834975, -2.32312431],\n",
       "       [-0.02743919,  2.95125952, -1.8973838 , ...,  1.34817843,\n",
       "         1.75710694, -2.17137682]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dot(W[0][\"weights\"])+W[0][\"bias\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the gradients of params at layer 0**\n",
    "\n",
    "observe how we need to feed **both** input and output to the gradients function. Output has to be in one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = F_gradients[0]([X_train, y_train_oh])[0]\n",
    "print (g.shape)\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We now inspect the distributions of weights, outputs and gradients of Layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_layer0_output():\n",
    "    weights=W[0][\"weights\"]\n",
    "    bias=W[0][\"bias\"]\n",
    "    O = (X_train.dot(weights)+bias).reshape(-1)\n",
    "    S = sigm(O)\n",
    "    plt.figure(figsize=(20,3))\n",
    "    plt.subplot(141)\n",
    "    plt.hist(O, bins=30, density=True);\n",
    "    plt.xlabel(\"$XW_{0}+b_{0}$\")\n",
    "    plt.subplot(142)\n",
    "    plt.hist(S, bins=30, density=True);\n",
    "    plt.xlabel(\"$sigm(XW_0+b_0)$\")\n",
    "    plt.subplot(143)\n",
    "    plt.hist(weights.reshape(-1), bins=30,density=True);\n",
    "    plt.xlabel(\"$W_{0}$\")\n",
    "    plt.subplot(144)\n",
    "    g = F_gradients[0]([X_train, y_train_oh])[0].reshape(-1)\n",
    "    plt.hist(g, bins=30,density=True);\n",
    "    plt.xlabel(\"gradients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_layer0_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
